# train_joint_improved.py
# æ”¹è¿›ç‰ˆå…³èŠ‚åˆ†å‰²è®­ç»ƒï¼Œä¸“é—¨å¤„ç†æåº¦ä¸å¹³è¡¡æ•°æ®

import torch
import torch.nn as nn
import os
from torch.utils.data import DataLoader, random_split, WeightedRandomSampler
import albumentations as A
from albumentations.pytorch import ToTensorV2
from tqdm import tqdm
import numpy as np

from dataset_joint import JointSegmentationDataset
from unet_smp import get_model
import config_joint as cfg


# æ”¹è¿›çš„Focal Lossï¼Œæ›´å¥½å¤„ç†ä¸å¹³è¡¡æ•°æ®
class ImprovedFocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = (1 - pt) ** self.gamma * ce_loss

        if self.alpha is not None:
            if isinstance(self.alpha, (float, int)):
                alpha_t = self.alpha
            else:
                # ä¿®å¤ç»´åº¦é—®é¢˜ï¼štargetséœ€è¦flattenå¹¶ä¸”alphaéœ€è¦åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
                targets_flat = targets.flatten()
                alpha_t = self.alpha[targets_flat].view_as(targets)
            focal_loss = alpha_t * focal_loss

        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss


def get_transform(train=True):
    """æ•°æ®å¢å¼ºç®¡é“ - å¯¹å…³èŠ‚åˆ†å‰²æ›´æ¿€è¿›çš„å¢å¼º"""
    if train:
        return A.Compose([
            A.Resize(512, 512),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.3),  # æ·»åŠ å‚ç›´ç¿»è½¬
            A.RandomRotate90(p=0.3),  # 90åº¦æ—‹è½¬
            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),
            A.ShiftScaleRotate(
                shift_limit=0.15,
                scale_limit=0.3,
                rotate_limit=45,
                p=0.7,
                border_mode=0
            ),
            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
            A.OneOf([
                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0),
                A.GridDistortion(p=1.0),
                A.OpticalDistortion(p=1.0),
            ], p=0.5),
            # ä¸“é—¨é’ˆå¯¹å°ç›®æ ‡çš„å¢å¼º
            A.OneOf([
                A.RandomCrop(height=400, width=400, p=1.0),
                A.CenterCrop(height=400, width=400, p=1.0),
            ], p=0.3),
            A.Resize(512, 512),  # ç¡®ä¿æœ€ç»ˆå°ºå¯¸
            A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
            ToTensorV2()
        ])
    else:
        return A.Compose([
            A.Resize(512, 512),
            A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
            ToTensorV2()
        ])


def calculate_sample_weights(dataset):
    """è®¡ç®—æ ·æœ¬æƒé‡ï¼Œç”¨äºå¹³è¡¡é‡‡æ ·"""
    weights = []

    print("è®¡ç®—æ ·æœ¬æƒé‡...")
    for i in tqdm(range(len(dataset))):
        _, mask = dataset[i]
        has_joint = (mask == 1).any().item()

        if has_joint:
            weights.append(10.0)  # é˜³æ€§æ ·æœ¬æƒé‡10å€
        else:
            weights.append(1.0)  # é˜´æ€§æ ·æœ¬æ­£å¸¸æƒé‡

    positive_count = sum(1 for w in weights if w > 1.0)
    print(f"é˜³æ€§æ ·æœ¬: {positive_count}, æƒé‡: 10.0")
    print(f"é˜´æ€§æ ·æœ¬: {len(weights) - positive_count}, æƒé‡: 1.0")

    return torch.tensor(weights, dtype=torch.float)


def train():
    print("=== Week 3: å…³èŠ‚äºŒåˆ†ç±»è®­ç»ƒ (æ”¹è¿›ç‰ˆ) ===")

    # æ•°æ®é›†å‡†å¤‡
    full_dataset = JointSegmentationDataset(transform=get_transform(train=True), only_positive=False)

    if len(full_dataset) == 0:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®æ ·æœ¬ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œæ–‡ä»¶ç»“æ„")
        return

    # è®¡ç®—æ ·æœ¬æƒé‡ç”¨äºå¹³è¡¡é‡‡æ ·
    sample_weights = calculate_sample_weights(full_dataset)

    # æ•°æ®é›†æ‹†åˆ†
    n_val = max(1, int(0.2 * len(full_dataset)))
    n_train = len(full_dataset) - n_val
    train_dataset, val_dataset = random_split(full_dataset, [n_train, n_val])

    # ä¸ºè®­ç»ƒé›†åˆ›å»ºåŠ æƒé‡‡æ ·å™¨
    train_indices = train_dataset.indices
    train_sample_weights = sample_weights[train_indices]
    weighted_sampler = WeightedRandomSampler(
        weights=train_sample_weights,
        num_samples=len(train_indices) * 2,  # å¢åŠ é‡‡æ ·æ•°é‡
        replacement=True
    )

    print(f"è®­ç»ƒé›†: {n_train}, éªŒè¯é›†: {n_val}")
    print(f"ä½¿ç”¨åŠ æƒé‡‡æ ·ï¼Œæ¯epoché‡‡æ ·: {len(train_indices) * 2} ä¸ªæ ·æœ¬")

    # æ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=cfg.BATCH_SIZE,
        sampler=weighted_sampler,  # ä½¿ç”¨åŠ æƒé‡‡æ ·
        num_workers=2,
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=cfg.BATCH_SIZE,
        shuffle=False,
        num_workers=2,
        pin_memory=True
    )

    # æ¨¡å‹åˆå§‹åŒ–
    model = get_model(cfg.NUM_CLASSES).to(cfg.DEVICE)

    # æ”¹è¿›çš„æŸå¤±å‡½æ•°ï¼šFocal Loss + å¼ºç±»åˆ«æƒé‡
    class_weights = torch.tensor([1.0, 50.0]).to(cfg.DEVICE)  # å…³èŠ‚ç±»æƒé‡50å€
    focal_loss = ImprovedFocalLoss(alpha=class_weights, gamma=2.0)
    ce_loss = nn.CrossEntropyLoss(weight=class_weights)

    def combined_loss(pred, target):
        return 0.7 * focal_loss(pred, target) + 0.3 * ce_loss(pred, target)

    # ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ - é™ä½å­¦ä¹ ç‡
    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', patience=3, factor=0.5, verbose=True, min_lr=1e-6
    )

    # æ—©åœæœºåˆ¶
    best_val_loss = float('inf')
    best_iou = 0.0
    patience_counter = 0

    print(f"å¼€å§‹è®­ç»ƒï¼Œç›®æ ‡epochs: {cfg.NUM_EPOCHS}")
    print("ä½¿ç”¨æ”¹è¿›ç­–ç•¥: Focal Loss + ç±»åˆ«æƒé‡ + åŠ æƒé‡‡æ ·")

    for epoch in range(1, cfg.NUM_EPOCHS + 1):
        # ========== è®­ç»ƒé˜¶æ®µ ==========
        model.train()
        train_loss = 0.0
        train_batches = 0

        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch:2d}/{cfg.NUM_EPOCHS} [Train]")
        for batch_idx, (images, masks) in enumerate(train_pbar):
            images = images.to(cfg.DEVICE, non_blocking=True)
            masks = masks.to(cfg.DEVICE, non_blocking=True)

            # å‰å‘ä¼ æ’­
            outputs = model(images)
            loss = combined_loss(outputs, masks)

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()

            # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

            optimizer.step()

            # ç»Ÿè®¡
            train_loss += loss.item()
            train_batches += 1

            # æ›´æ–°è¿›åº¦æ¡
            train_pbar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'avg_loss': f'{train_loss / train_batches:.4f}'
            })

        avg_train_loss = train_loss / train_batches

        # ========== éªŒè¯é˜¶æ®µ ==========
        model.eval()
        val_loss = 0.0
        val_batches = 0

        # è®¡ç®—IoUæŒ‡æ ‡
        total_intersection = 0
        total_union = 0

        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f"Epoch {epoch:2d}/{cfg.NUM_EPOCHS} [Val]  ")
            for images, masks in val_pbar:
                images = images.to(cfg.DEVICE, non_blocking=True)
                masks = masks.to(cfg.DEVICE, non_blocking=True)

                outputs = model(images)
                loss = combined_loss(outputs, masks)

                val_loss += loss.item()
                val_batches += 1

                # è®¡ç®—IoU (å…³èŠ‚ç±»åˆ«)
                preds = outputs.argmax(dim=1)
                intersection = ((preds == 1) & (masks == 1)).sum().item()
                union = ((preds == 1) | (masks == 1)).sum().item()

                total_intersection += intersection
                total_union += union

                val_pbar.set_postfix({'val_loss': f'{loss.item():.4f}'})

        avg_val_loss = val_loss / val_batches
        val_iou = total_intersection / total_union if total_union > 0 else 0.0

        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(avg_val_loss)
        current_lr = optimizer.param_groups[0]['lr']

        print(f"Epoch {epoch:2d}: train_loss={avg_train_loss:.4f}, val_loss={avg_val_loss:.4f}, "
              f"val_IoU={val_iou:.4f}, lr={current_lr:.2e}")

        # ========== æ¨¡å‹ä¿å­˜ç­–ç•¥ ==========
        # åŒæ—¶è€ƒè™‘losså’ŒIoU
        save_model = False
        if val_iou > best_iou:
            best_iou = val_iou
            save_model = True
            patience_counter = 0
        elif avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            save_model = True
            patience_counter = 0
        else:
            patience_counter += 1

        if save_model:
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_loss': best_val_loss,
                'best_iou': best_iou,
                'class_weights': class_weights
            }, cfg.MODEL_NAME)
            print(f"âœ… æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (IoU: {best_iou:.4f}, Loss: {best_val_loss:.4f})")
        else:
            print(f"â³ æ€§èƒ½æœªæ”¹å–„ ({patience_counter}/{cfg.ES_PATIENCE})")

        if patience_counter >= cfg.ES_PATIENCE:
            print(f"ğŸ›‘ æ—©åœè§¦å‘ at epoch {epoch}")
            break

    print(f"ğŸ‰ è®­ç»ƒå®Œæˆ! æœ€ä½³IoU: {best_iou:.4f}, æœ€ä½³æŸå¤±: {best_val_loss:.4f}")
    print(f"æœ€ä½³æ¨¡å‹ä¿å­˜ä½ç½®: {cfg.MODEL_NAME}")


if __name__ == "__main__":
    train()
# diagnose_joint_model.py

import torch
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import rcParams
import cv2
from albumentations import Compose, Resize, Normalize
from albumentations.pytorch import ToTensorV2

from dataset_joint import JointSegmentationDataset
from unet_smp import get_model
import config_joint as cfg

# è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡æ˜¾ç¤º
rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS']
rcParams['axes.unicode_minus'] = False


def get_eval_transform():
    """éªŒè¯ç”¨çš„æ•°æ®é¢„å¤„ç†"""
    return Compose([
        Resize(512, 512),
        Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
        ToTensorV2()
    ])


def analyze_joint_distribution():
    """è¯¦ç»†åˆ†æå…³èŠ‚æ•°æ®åˆ†å¸ƒ"""
    print("=" * 60)
    print("ğŸ” è¯¦ç»†åˆ†æå…³èŠ‚æ•°æ®åˆ†å¸ƒ")
    print("=" * 60)

    dataset = JointSegmentationDataset(transform=get_eval_transform(), only_positive=False)

    positive_samples = []
    negative_samples = []

    print("åˆ†ææ‰€æœ‰æ ·æœ¬...")
    for i in range(len(dataset)):
        _, mask = dataset[i]
        mask_np = mask.cpu().numpy()
        joint_pixels = (mask_np == 1).sum()

        if joint_pixels > 0:
            positive_samples.append((i, joint_pixels))
        else:
            negative_samples.append(i)

    print(f"\nğŸ“Š æ ·æœ¬åˆ†å¸ƒ:")
    print(f"é˜³æ€§æ ·æœ¬ (æœ‰å…³èŠ‚): {len(positive_samples)}")
    print(f"é˜´æ€§æ ·æœ¬ (æ— å…³èŠ‚): {len(negative_samples)}")

    if positive_samples:
        print(f"\nğŸ” é˜³æ€§æ ·æœ¬è¯¦æƒ…:")
        positive_samples.sort(key=lambda x: x[1], reverse=True)  # æŒ‰åƒç´ æ•°æ’åº
        for i, (idx, pixels) in enumerate(positive_samples[:10]):
            print(f"  Sample {idx}: {pixels:,} å…³èŠ‚åƒç´ ")

    return positive_samples, negative_samples


def test_model_predictions():
    """æµ‹è¯•æ¨¡å‹é¢„æµ‹è¡Œä¸º"""
    print("\n" + "=" * 60)
    print("ğŸ¤– æµ‹è¯•æ¨¡å‹é¢„æµ‹è¡Œä¸º")
    print("=" * 60)

    # åŠ è½½æ•°æ®é›†å’Œæ¨¡å‹
    dataset = JointSegmentationDataset(transform=get_eval_transform(), only_positive=False)

    try:
        model = get_model(cfg.NUM_CLASSES).to(cfg.DEVICE)
        checkpoint = torch.load(cfg.MODEL_NAME, map_location=cfg.DEVICE, weights_only=False)
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        model.eval()
        print(f"âœ… æ¨¡å‹å·²åŠ è½½: {cfg.MODEL_NAME}")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    # åˆ†ææ‰€æœ‰æ ·æœ¬çš„é¢„æµ‹ç»“æœ
    all_predictions = []
    all_gt_labels = []

    print("\nåˆ†ææ¨¡å‹é¢„æµ‹...")
    with torch.no_grad():
        for i in range(min(50, len(dataset))):  # åˆ†æå‰50ä¸ªæ ·æœ¬
            img, gt_mask = dataset[i]

            # æ¨¡å‹é¢„æµ‹
            img_batch = img.unsqueeze(0).to(cfg.DEVICE)
            output = model(img_batch)
            pred_probs = torch.softmax(output, dim=1)
            pred_mask = output.argmax(dim=1).squeeze().cpu().numpy()

            # ç»Ÿè®¡é¢„æµ‹ç»“æœ
            gt_has_joint = (gt_mask == 1).any().item()
            pred_has_joint = (pred_mask == 1).any()

            max_joint_prob = pred_probs[0, 1].max().item()  # å…³èŠ‚ç±»åˆ«çš„æœ€å¤§æ¦‚ç‡

            all_predictions.append({
                'sample_idx': i,
                'gt_has_joint': gt_has_joint,
                'pred_has_joint': pred_has_joint,
                'max_joint_prob': max_joint_prob,
                'gt_joint_pixels': (gt_mask == 1).sum().item(),
                'pred_joint_pixels': (pred_mask == 1).sum()
            })

            if gt_has_joint:
                all_gt_labels.append(1)
            else:
                all_gt_labels.append(0)

    # åˆ†æç»“æœ
    print(f"\nğŸ“Š é¢„æµ‹ç»Ÿè®¡ (å‰{len(all_predictions)}ä¸ªæ ·æœ¬):")

    # é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ
    pred_joint_count = sum(1 for p in all_predictions if p['pred_has_joint'])
    pred_bg_count = len(all_predictions) - pred_joint_count

    print(f"æ¨¡å‹é¢„æµ‹åˆ†å¸ƒ:")
    print(f"  é¢„æµ‹ä¸ºå…³èŠ‚: {pred_joint_count}")
    print(f"  é¢„æµ‹ä¸ºèƒŒæ™¯: {pred_bg_count}")

    # æ¦‚ç‡åˆ†å¸ƒ
    joint_probs = [p['max_joint_prob'] for p in all_predictions]
    print(f"\nå…³èŠ‚æ¦‚ç‡ç»Ÿè®¡:")
    print(f"  æœ€å¤§æ¦‚ç‡: {max(joint_probs):.4f}")
    print(f"  å¹³å‡æ¦‚ç‡: {np.mean(joint_probs):.4f}")
    print(f"  æ¦‚ç‡>0.5çš„æ ·æœ¬: {sum(1 for p in joint_probs if p > 0.5)}")
    print(f"  æ¦‚ç‡>0.1çš„æ ·æœ¬: {sum(1 for p in joint_probs if p > 0.1)}")

    # æŒ‰GTåˆ†ç»„åˆ†æ
    positive_preds = [p for p in all_predictions if p['gt_has_joint']]
    negative_preds = [p for p in all_predictions if not p['gt_has_joint']]

    print(f"\nğŸ”´ é˜³æ€§æ ·æœ¬ (GTæœ‰å…³èŠ‚, {len(positive_preds)}ä¸ª):")
    if positive_preds:
        pos_probs = [p['max_joint_prob'] for p in positive_preds]
        print(f"  å¹³å‡å…³èŠ‚æ¦‚ç‡: {np.mean(pos_probs):.4f}")
        print(f"  æœ€å¤§å…³èŠ‚æ¦‚ç‡: {max(pos_probs):.4f}")
        print(f"  é¢„æµ‹æ­£ç¡®çš„: {sum(1 for p in positive_preds if p['pred_has_joint'])}")

    print(f"\nâšª é˜´æ€§æ ·æœ¬ (GTæ— å…³èŠ‚, {len(negative_preds)}ä¸ª):")
    if negative_preds:
        neg_probs = [p['max_joint_prob'] for p in negative_preds]
        print(f"  å¹³å‡å…³èŠ‚æ¦‚ç‡: {np.mean(neg_probs):.4f}")
        print(f"  æœ€å¤§å…³èŠ‚æ¦‚ç‡: {max(neg_probs):.4f}")
        print(f"  é¢„æµ‹æ­£ç¡®çš„: {sum(1 for p in negative_preds if not p['pred_has_joint'])}")

    return all_predictions


def visualize_positive_samples():
    """ä¸“é—¨å¯è§†åŒ–æœ‰å…³èŠ‚çš„é˜³æ€§æ ·æœ¬"""
    print("\n" + "=" * 60)
    print("ğŸ¨ å¯è§†åŒ–é˜³æ€§æ ·æœ¬")
    print("=" * 60)

    dataset = JointSegmentationDataset(transform=get_eval_transform(), only_positive=False)

    # æ‰¾åˆ°æ‰€æœ‰é˜³æ€§æ ·æœ¬
    positive_indices = []
    for i in range(len(dataset)):
        _, mask = dataset[i]
        if (mask == 1).any():
            positive_indices.append(i)

    print(f"æ‰¾åˆ° {len(positive_indices)} ä¸ªé˜³æ€§æ ·æœ¬")

    if len(positive_indices) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°é˜³æ€§æ ·æœ¬")
        return

    # åŠ è½½æ¨¡å‹
    try:
        model = get_model(cfg.NUM_CLASSES).to(cfg.DEVICE)
        checkpoint = torch.load(cfg.MODEL_NAME, map_location=cfg.DEVICE, weights_only=False)
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        model.eval()
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    # å¯è§†åŒ–å‰4ä¸ªé˜³æ€§æ ·æœ¬
    n_samples = min(4, len(positive_indices))
    fig, axes = plt.subplots(n_samples, 4, figsize=(16, 4 * n_samples))

    if n_samples == 1:
        axes = axes.reshape(1, -1)

    with torch.no_grad():
        for i, idx in enumerate(positive_indices[:n_samples]):
            img, gt_mask = dataset[idx]

            # æ¨¡å‹é¢„æµ‹
            img_batch = img.unsqueeze(0).to(cfg.DEVICE)
            output = model(img_batch)
            pred_probs = torch.softmax(output, dim=1)
            pred_mask = output.argmax(dim=1).squeeze().cpu().numpy()

            # åå½’ä¸€åŒ–å›¾åƒ
            img_display = img.permute(1, 2, 0).cpu().numpy()
            img_display = (img_display + 1.0) / 2.0
            img_display = np.clip(img_display, 0, 1)

            gt_mask_np = gt_mask.cpu().numpy()
            joint_prob = pred_probs[0, 1].cpu().numpy()

            # è®¡ç®—æŒ‡æ ‡
            gt_joint_pixels = (gt_mask_np == 1).sum()
            pred_joint_pixels = (pred_mask == 1).sum()
            max_prob = joint_prob.max()

            # æ˜¾ç¤ºå›¾åƒ
            axes[i, 0].imshow(img_display)
            axes[i, 0].set_title(f'Sample {idx}\nOriginal')
            axes[i, 0].axis('off')

            axes[i, 1].imshow(gt_mask_np, cmap='gray', vmin=0, vmax=1)
            axes[i, 1].set_title(f'GT: {gt_joint_pixels} pixels')
            axes[i, 1].axis('off')

            axes[i, 2].imshow(pred_mask, cmap='gray', vmin=0, vmax=1)
            axes[i, 2].set_title(f'Pred: {pred_joint_pixels} pixels')
            axes[i, 2].axis('off')

            axes[i, 3].imshow(joint_prob, cmap='hot', vmin=0, vmax=1)
            axes[i, 3].set_title(f'Joint Prob\nMax: {max_prob:.3f}')
            axes[i, 3].axis('off')

            print(f"Sample {idx}: GT={gt_joint_pixels}, Pred={pred_joint_pixels}, MaxProb={max_prob:.3f}")

    plt.tight_layout()
    plt.suptitle('Joint Segmentation: Positive Samples Analysis', fontsize=14, y=0.98)
    plt.savefig('joint_positive_samples_analysis.png', dpi=150, bbox_inches='tight')
    plt.show()
    print(f"âœ… é˜³æ€§æ ·æœ¬åˆ†æå›¾å·²ä¿å­˜: joint_positive_samples_analysis.png")


def suggest_solutions():
    """å»ºè®®è§£å†³æ–¹æ¡ˆ"""
    print("\n" + "=" * 60)
    print("ğŸ’¡ é—®é¢˜è¯Šæ–­ä¸è§£å†³å»ºè®®")
    print("=" * 60)

    print("å¯èƒ½çš„é—®é¢˜:")
    print("1. æ•°æ®æåº¦ä¸å¹³è¡¡ (782.8:1) å¯¼è‡´æ¨¡å‹é€€åŒ–")
    print("2. å­¦ä¹ ç‡è¿‡é«˜ï¼Œæ¨¡å‹è¿‡å¿«æ”¶æ•›åˆ°æ‡’æƒ°ç­–ç•¥")
    print("3. æŸå¤±å‡½æ•°æƒé‡ä¸å½“")
    print("4. è®­ç»ƒepochsä¸è¶³")

    print("\nå»ºè®®è§£å†³æ–¹æ¡ˆ:")
    print("1. é‡æ–°è®­ç»ƒæ—¶ä½¿ç”¨æ›´å¼ºçš„ç±»åˆ«æƒé‡:")
    print("   - å°†å…³èŠ‚ç±»åˆ«æƒé‡æé«˜åˆ° 50-100")
    print("2. é™ä½å­¦ä¹ ç‡:")
    print("   - LR = 5e-4 æˆ– 1e-4")
    print("3. å¢åŠ Focal Loss:")
    print("   - æ›´å¥½å¤„ç†ä¸å¹³è¡¡æ•°æ®")
    print("4. æ•°æ®å¢å¼º:")
    print("   - å¯¹é˜³æ€§æ ·æœ¬è¿›è¡Œé‡å¤é‡‡æ ·")
    print("5. è°ƒæ•´è®­ç»ƒç­–ç•¥:")
    print("   - å…ˆåœ¨é˜³æ€§æ ·æœ¬ä¸Šé¢„è®­ç»ƒ")


if __name__ == "__main__":
    # åˆ†ææ•°æ®åˆ†å¸ƒ
    positive_samples, negative_samples = analyze_joint_distribution()

    # æµ‹è¯•æ¨¡å‹é¢„æµ‹
    predictions = test_model_predictions()

    # å¯è§†åŒ–é˜³æ€§æ ·æœ¬
    visualize_positive_samples()

    # ç»™å‡ºå»ºè®®
    suggest_solutions()